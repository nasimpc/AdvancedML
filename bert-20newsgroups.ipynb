{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31287,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n## 1. Imports & Environment Setup","metadata":{}},{"cell_type":"code","source":"\n\nimport os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"  # Prevent fork warnings with DataLoader\n\nimport json\nimport random\nimport time\nfrom typing import Tuple\nfrom dataclasses import dataclass, field\nfrom collections import Counter\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torch.amp import GradScaler, autocast\nfrom torch.optim import AdamW\n\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    AutoConfig,\n    get_linear_schedule_with_warmup\n)\nfrom sklearn.metrics import (\n    accuracy_score,\n    precision_recall_fscore_support,\n    classification_report,\n    confusion_matrix\n)\nfrom tqdm import tqdm\n\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    num_gpus = torch.cuda.device_count()\n    print(f\"Number of GPUs: {num_gpus}\")\n    for i in range(num_gpus):\n        print(f\"  GPU {i}: {torch.cuda.get_device_name(i)} \"\n              f\"({torch.cuda.get_device_properties(i).total_memory / 1024**3:.1f} GB)\")\n    torch.backends.cudnn.benchmark = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T13:22:24.712294Z","iopub.execute_input":"2026-02-19T13:22:24.712941Z","iopub.status.idle":"2026-02-19T13:22:47.004419Z","shell.execute_reply.started":"2026-02-19T13:22:24.712912Z","shell.execute_reply":"2026-02-19T13:22:47.003594Z"}},"outputs":[{"name":"stdout","text":"PyTorch version: 2.9.0+cu126\nCUDA available: True\nNumber of GPUs: 2\n  GPU 0: Tesla T4 (14.6 GB)\n  GPU 1: Tesla T4 (14.6 GB)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## 2. Configuration","metadata":{}},{"cell_type":"code","source":"\n@dataclass\nclass Config:\n    \"\"\"Configuration class with all hyperparameters and settings.\"\"\"\n    \n    # Model Configuration\n    model_name: str = \"answerdotai/ModernBERT-large\"\n    num_labels: int = 20\n    \n    # Training Hyperparameters\n    learning_rate: float = 3e-5\n    batch_size: int = 16  # Per-GPU batch size (total = batch_size × num_gpus)\n    num_epochs: int = 4\n    warmup_ratio: float = 0.1\n    weight_decay: float = 0.01\n    max_grad_norm: float = 1.0\n    \n    # Layer Freezing\n    freeze_layers: bool = True\n    freeze_ratio: float = 0.5  # Freeze bottom 50% of encoder layers (14/28)\n    \n    # Data Configuration\n    dataset_name: str = \"SetFit/20_newsgroups\"\n    max_length: int = 256  \n    \n    # Training Settings\n    seed: int = 42\n    use_fp16: bool = True\n    save_model: bool = True\n    output_dir: str = \"./output\"\n    \n    # Device (auto-detected)\n    device: str = field(default_factory=lambda: \"cuda\" if torch.cuda.is_available() else \"cpu\")\n    num_gpus: int = field(default_factory=lambda: torch.cuda.device_count() if torch.cuda.is_available() else 0)\n    \n    def __post_init__(self):\n        if self.device == \"cpu\":\n            self.use_fp16 = False\n        # Scale batch size across GPUs\n        self.total_batch_size = self.batch_size * max(1, self.num_gpus)\n            \n    def to_dict(self) -> dict:\n        return {\n            \"model_name\": self.model_name,\n            \"num_labels\": self.num_labels,\n            \"learning_rate\": self.learning_rate,\n            \"batch_size_per_gpu\": self.batch_size,\n            \"num_gpus\": self.num_gpus,\n            \"total_batch_size\": self.total_batch_size,\n            \"num_epochs\": self.num_epochs,\n            \"warmup_ratio\": self.warmup_ratio,\n            \"weight_decay\": self.weight_decay,\n            \"max_length\": self.max_length,\n            \"freeze_layers\": self.freeze_layers,\n            \"freeze_ratio\": self.freeze_ratio,\n            \"seed\": self.seed,\n            \"use_fp16\": self.use_fp16,\n            \"device\": self.device,\n        }\n\n# Initialize configuration\nconfig = Config()\n\nprint(\"Configuration:\")\nfor key, value in config.to_dict().items():\n    print(f\"  {key}: {value}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T13:22:47.005850Z","iopub.execute_input":"2026-02-19T13:22:47.006359Z","iopub.status.idle":"2026-02-19T13:22:47.016099Z","shell.execute_reply.started":"2026-02-19T13:22:47.006331Z","shell.execute_reply":"2026-02-19T13:22:47.015339Z"}},"outputs":[{"name":"stdout","text":"Configuration:\n  model_name: answerdotai/ModernBERT-large\n  num_labels: 20\n  learning_rate: 3e-05\n  batch_size_per_gpu: 16\n  num_gpus: 2\n  total_batch_size: 32\n  num_epochs: 4\n  warmup_ratio: 0.1\n  weight_decay: 0.01\n  max_length: 256\n  freeze_layers: True\n  freeze_ratio: 0.5\n  seed: 42\n  use_fp16: True\n  device: cuda\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## 3. Dataset Exploration & Statistical Overview\n\n","metadata":{}},{"cell_type":"code","source":"\ndef explore_dataset(config):\n    \"\"\"Load and display comprehensive dataset statistics.\"\"\"\n    print(\"\\n\" + \"=\"*70)\n    print(\"DATASET EXPLORATION: 20 Newsgroups\")\n    print(\"=\"*70)\n    \n    # Load raw dataset\n    dataset = load_dataset(config.dataset_name)\n    train_data = dataset['train']\n    test_data = dataset['test']\n    \n    label_names = [\n        'alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc',\n        'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x',\n        'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball',\n        'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med',\n        'sci.space', 'soc.religion.christian', 'talk.politics.guns',\n        'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc'\n    ]\n    \n    # --- Basic Info ---\n    print(f\"\\n{'─'*50}\")\n    print(f\"  Dataset: {config.dataset_name}\")\n    print(f\"  Number of classes: {len(label_names)}\")\n    print(f\"  Train samples: {len(train_data):,}\")\n    print(f\"  Test samples:  {len(test_data):,}\")\n    print(f\"  Total samples: {len(train_data) + len(test_data):,}\")\n    print(f\"  Features: {list(train_data.features.keys())}\")\n    print(f\"{'─'*50}\")\n    \n    # --- Class Distribution ---\n    print(f\"\\n{'─'*50}\")\n    print(\"  CLASS DISTRIBUTION\")\n    print(f\"{'─'*50}\")\n    \n    train_labels = train_data['label']\n    test_labels = test_data['label']\n    train_counts = Counter(train_labels)\n    test_counts = Counter(test_labels)\n    \n    print(f\"\\n  {'Category':<35} {'Train':>6} {'Test':>6} {'Total':>6}\")\n    print(f\"  {'─'*55}\")\n    for i, name in enumerate(label_names):\n        tr = train_counts.get(i, 0)\n        te = test_counts.get(i, 0)\n        bar = '█' * (tr // 20)\n        print(f\"  {name:<35} {tr:>6} {te:>6} {tr+te:>6}  {bar}\")\n    \n    print(f\"  {'─'*55}\")\n    print(f\"  {'TOTAL':<35} {len(train_data):>6} {len(test_data):>6} {len(train_data)+len(test_data):>6}\")\n    \n    # Class balance metrics\n    train_counts_list = [train_counts.get(i, 0) for i in range(len(label_names))]\n    print(f\"\\n  Train class balance:\")\n    print(f\"    Min samples/class: {min(train_counts_list)}\")\n    print(f\"    Max samples/class: {max(train_counts_list)}\")\n    print(f\"    Mean samples/class: {np.mean(train_counts_list):.1f}\")\n    print(f\"    Std samples/class: {np.std(train_counts_list):.1f}\")\n    print(f\"    Imbalance ratio (max/min): {max(train_counts_list)/max(min(train_counts_list),1):.2f}\")\n    \n    # --- Text Length Statistics ---\n    print(f\"\\n{'─'*50}\")\n    print(\"  TEXT LENGTH STATISTICS (Training Set)\")\n    print(f\"{'─'*50}\")\n    \n    texts = train_data['text']\n    char_lengths = [len(t) for t in texts]\n    word_lengths = [len(t.split()) for t in texts]\n    \n    for metric_name, lengths in [(\"Character lengths\", char_lengths), (\"Word counts\", word_lengths)]:\n        arr = np.array(lengths)\n        print(f\"\\n  {metric_name}:\")\n        print(f\"    Min:    {arr.min():>8,}\")\n        print(f\"    Max:    {arr.max():>8,}\")\n        print(f\"    Mean:   {arr.mean():>8,.1f}\")\n        print(f\"    Median: {np.median(arr):>8,.1f}\")\n        print(f\"    Std:    {arr.std():>8,.1f}\")\n        print(f\"    P25:    {np.percentile(arr, 25):>8,.1f}\")\n        print(f\"    P75:    {np.percentile(arr, 75):>8,.1f}\")\n        print(f\"    P95:    {np.percentile(arr, 95):>8,.1f}\")\n    \n    # Token-level stats with tokenizer\n    print(f\"\\n  Tokenized lengths (using {config.model_name} tokenizer):\")\n    tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n    \n    # Sample for speed (full tokenization on large dataset is slow)\n    sample_size = min(2000, len(texts))\n    sample_texts = random.sample(texts, sample_size)\n    token_lengths = [len(tokenizer.encode(t)) for t in sample_texts]\n    arr = np.array(token_lengths)\n    \n    print(f\"    (Sampled {sample_size:,} documents)\")\n    print(f\"    Min:    {arr.min():>8,}\")\n    print(f\"    Max:    {arr.max():>8,}\")\n    print(f\"    Mean:   {arr.mean():>8,.1f}\")\n    print(f\"    Median: {np.median(arr):>8,.1f}\")\n    print(f\"    P95:    {np.percentile(arr, 95):>8,.1f}\")\n    \n    # Coverage at different max_length thresholds\n    print(f\"\\n  Token coverage at different max_length:\")\n    for ml in [128, 256, 512]:\n        coverage = (arr <= ml).sum() / len(arr) * 100\n        print(f\"    max_length={ml}: {coverage:.1f}% of documents fully covered\")\n    print(f\"    → Using max_length={config.max_length}\")\n    \n    # --- Sample Documents ---\n    print(f\"\\n{'─'*50}\")\n    print(\"  SAMPLE DOCUMENTS (first 200 chars)\")\n    print(f\"{'─'*50}\")\n    \n    # Show 1 sample per first 5 classes\n    for i in range(min(5, len(label_names))):\n        # Find first document with this label\n        for j, lbl in enumerate(train_labels):\n            if lbl == i:\n                text_preview = texts[j][:200].replace('\\n', ' ')\n                print(f\"\\n  [{label_names[i]}]\")\n                print(f\"  \\\"{text_preview}...\\\"\")\n                break\n    \n    print(f\"\\n{'─'*50}\")\n    print(f\"  (Showing 5 of {len(label_names)} classes)\")\n    print(\"=\"*70 + \"\\n\")\n    \n    return dataset\n\n\n# Run dataset exploration\ndataset = explore_dataset(config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T13:22:47.017171Z","iopub.execute_input":"2026-02-19T13:22:47.017486Z","iopub.status.idle":"2026-02-19T13:23:00.909344Z","shell.execute_reply.started":"2026-02-19T13:22:47.017455Z","shell.execute_reply":"2026-02-19T13:23:00.908565Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nDATASET EXPLORATION: 20 Newsgroups\n======================================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/734 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2e7fe8ecee34416823ad2ffa502c3a6"}},"metadata":{}},{"name":"stderr","text":"Repo card metadata block was not found. Setting CardData to empty.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"train.jsonl:   0%|          | 0.00/14.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e71baecdba848db84c77945452a42cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test.jsonl:   0%|          | 0.00/8.91M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61c0101afab04b9ea23b71e9a1b3c86b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/11314 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25aac8aaeb0144dd85ce9183ce48650d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/7532 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ba415dd30a849f9a207fb1e1b324c11"}},"metadata":{}},{"name":"stdout","text":"\n──────────────────────────────────────────────────\n  Dataset: SetFit/20_newsgroups\n  Number of classes: 20\n  Train samples: 11,314\n  Test samples:  7,532\n  Total samples: 18,846\n  Features: ['text', 'label', 'label_text']\n──────────────────────────────────────────────────\n\n──────────────────────────────────────────────────\n  CLASS DISTRIBUTION\n──────────────────────────────────────────────────\n\n  Category                             Train   Test  Total\n  ───────────────────────────────────────────────────────\n  alt.atheism                            480    319    799  ████████████████████████\n  comp.graphics                          584    389    973  █████████████████████████████\n  comp.os.ms-windows.misc                591    394    985  █████████████████████████████\n  comp.sys.ibm.pc.hardware               590    392    982  █████████████████████████████\n  comp.sys.mac.hardware                  578    385    963  ████████████████████████████\n  comp.windows.x                         593    395    988  █████████████████████████████\n  misc.forsale                           585    390    975  █████████████████████████████\n  rec.autos                              594    396    990  █████████████████████████████\n  rec.motorcycles                        598    398    996  █████████████████████████████\n  rec.sport.baseball                     597    397    994  █████████████████████████████\n  rec.sport.hockey                       600    399    999  ██████████████████████████████\n  sci.crypt                              595    396    991  █████████████████████████████\n  sci.electronics                        591    393    984  █████████████████████████████\n  sci.med                                594    396    990  █████████████████████████████\n  sci.space                              593    394    987  █████████████████████████████\n  soc.religion.christian                 599    398    997  █████████████████████████████\n  talk.politics.guns                     546    364    910  ███████████████████████████\n  talk.politics.mideast                  564    376    940  ████████████████████████████\n  talk.politics.misc                     465    310    775  ███████████████████████\n  talk.religion.misc                     377    251    628  ██████████████████\n  ───────────────────────────────────────────────────────\n  TOTAL                                11314   7532  18846\n\n  Train class balance:\n    Min samples/class: 377\n    Max samples/class: 600\n    Mean samples/class: 565.7\n    Std samples/class: 56.8\n    Imbalance ratio (max/min): 1.59\n\n──────────────────────────────────────────────────\n  TEXT LENGTH STATISTICS (Training Set)\n──────────────────────────────────────────────────\n","output_type":"stream"},{"name":"stderr","text":"Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n","output_type":"stream"},{"name":"stdout","text":"\n  Character lengths:\n    Min:           0\n    Max:      74,878\n    Mean:    1,218.1\n    Median:    491.0\n    Std:     4,038.1\n    P25:       237.0\n    P75:       984.8\n    P95:     3,494.4\n\n  Word counts:\n    Min:           0\n    Max:      11,765\n    Mean:      185.8\n    Median:     83.0\n    Std:       523.9\n    P25:        40.0\n    P75:       167.0\n    P95:       572.4\n\n  Tokenized lengths (using answerdotai/ModernBERT-large tokenizer):\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0682dc8283684c1d82e093dcd0ab4953"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64db2308e1fd4f4a99c3af4a45c6e875"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbff0f46956b4a6ab284bae8f36cfe3a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/694 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18062e757e374115b64b45252e5431bc"}},"metadata":{}},{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (37451 > 8192). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"name":"stdout","text":"    (Sampled 2,000 documents)\n    Min:           2\n    Max:      46,467\n    Mean:      356.2\n    Median:    135.0\n    P95:       944.2\n\n  Token coverage at different max_length:\n    max_length=128: 48.2% of documents fully covered\n    max_length=256: 73.5% of documents fully covered\n    max_length=512: 89.8% of documents fully covered\n    → Using max_length=256\n\n──────────────────────────────────────────────────\n  SAMPLE DOCUMENTS (first 200 chars)\n──────────────────────────────────────────────────\n\n  [alt.atheism]\n  \" Don't be so sure.  Look what happened to Japanese citizens in the US during World War II.  If you're prepared to say \"Let's round these people up and stick them in a concentration camp without trial\"...\"\n\n  [comp.graphics]\n  \" Do you have Weitek's address/phone number?  I'd like to get some information about this chip. ...\"\n\n  [comp.os.ms-windows.misc]\n  \"I have win 3.0 and downloaded several icons and BMP's but I can't figure out how to change the \"wallpaper\" or use the icons.  Any help would be appreciated.   Thanx,  -Brando...\"\n\n  [comp.sys.ibm.pc.hardware]\n  \"                                                                       ALL this shows is that YOU don't know much about SCSI.  SCSI-1 {with a SCSI-1 controler chip} range is indeed 0-5MB/s and that is...\"\n\n  [comp.sys.mac.hardware]\n  \"A fair number of brave souls who upgraded their SI clock oscillator have shared their experiences for this poll. Please send a brief message detailing your experiences with the procedure. Top speed at...\"\n\n──────────────────────────────────────────────────\n  (Showing 5 of 20 classes)\n======================================================================\n\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## 4. Data Loading & Tokenization","metadata":{}},{"cell_type":"code","source":"\n\n\"\"\"\nData Loading and Preprocessing for 20 Newsgroups\n\nDesign Decisions:\n-----------------\n1. Tokenization: ModernBERT-large tokenizer\n2. Padding: max_length for uniform batch shapes (better for DataParallel)\n3. DataLoader: 4 workers per GPU, pin memory\n\"\"\"\n\ndef get_label_names() -> list:\n    \"\"\"Get the 20 newsgroup category names.\"\"\"\n    return [\n        'alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc',\n        'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x',\n        'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball',\n        'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med',\n        'sci.space', 'soc.religion.christian', 'talk.politics.guns',\n        'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc'\n    ]\n\n\ndef load_and_prepare_data(config, dataset=None) -> Tuple[DataLoader, DataLoader]:\n    \"\"\"Load 20 newsgroups dataset, tokenize, and create DataLoaders.\"\"\"\n    print(f\"\\nPreparing data for training...\")\n    \n    # Use pre-loaded dataset if available (from exploration step)\n    if dataset is None:\n        dataset = load_dataset(config.dataset_name)\n    \n    train_dataset = dataset['train']\n    test_dataset = dataset['test']\n    \n    print(f\"  Train size: {len(train_dataset)}\")\n    print(f\"  Test size: {len(test_dataset)}\")\n    \n    # Initialize tokenizer\n    tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n    \n    def tokenize_function(examples):\n        return tokenizer(\n            examples['text'],\n            truncation=True,\n            padding='max_length',\n            max_length=config.max_length,\n            return_tensors=None\n        )\n    \n    # Apply tokenization\n    print(\"  Tokenizing datasets...\")\n    train_dataset = train_dataset.map(tokenize_function, batched=True, desc=\"Tokenizing train\")\n    test_dataset = test_dataset.map(tokenize_function, batched=True, desc=\"Tokenizing test\")\n    \n    # Set format for PyTorch\n    columns = ['input_ids', 'attention_mask', 'label']\n    train_dataset.set_format(type='torch', columns=columns)\n    test_dataset.set_format(type='torch', columns=columns)\n    \n    # DataLoader config — use total_batch_size (accounts for multi-GPU)\n    num_workers = 4 if config.device == 'cuda' else 0\n    \n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=config.total_batch_size,\n        shuffle=True,\n        num_workers=num_workers,\n        pin_memory=True if config.device == 'cuda' else False,\n        drop_last=True  # Avoids uneven batch splits across GPUs\n    )\n    \n    test_loader = DataLoader(\n        test_dataset,\n        batch_size=config.total_batch_size,\n        shuffle=False,\n        num_workers=num_workers,\n        pin_memory=True if config.device == 'cuda' else False\n    )\n    \n    print(f\"  DataLoaders ready — Train batches: {len(train_loader)}, Test batches: {len(test_loader)}\")\n    \n    \n    return train_loader, test_loader\n\n\n# Load data (reuses the dataset from exploration to avoid re-downloading)\ntrain_loader, test_loader = load_and_prepare_data(config, dataset=dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T13:23:00.911253Z","iopub.execute_input":"2026-02-19T13:23:00.911569Z","iopub.status.idle":"2026-02-19T13:23:19.479022Z","shell.execute_reply.started":"2026-02-19T13:23:00.911515Z","shell.execute_reply":"2026-02-19T13:23:19.478435Z"}},"outputs":[{"name":"stdout","text":"\nPreparing data for training...\n  Train size: 11314\n  Test size: 7532\n  Tokenizing datasets...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Tokenizing train:   0%|          | 0/11314 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7db555eefcd14628bc8f3487177553e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing test:   0%|          | 0/7532 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4dc8c8fa27f4018a2b673497621e063"}},"metadata":{}},{"name":"stdout","text":"  DataLoaders ready — Train batches: 353, Test batches: 236\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## 5. Model\n","metadata":{}},{"cell_type":"code","source":"\ndef get_model(config):\n    \"\"\"Initialize ModernBERT-large with layer freezing and optional DataParallel.\"\"\"\n    print(f\"\\nLoading model: {config.model_name}\")\n    print(f\"  Number of classes: {config.num_labels}\")\n    \n    model_config = AutoConfig.from_pretrained(\n        config.model_name,\n        num_labels=config.num_labels,\n        finetuning_task=\"text-classification\"\n    )\n    \n    model = AutoModelForSequenceClassification.from_pretrained(\n        config.model_name,\n        config=model_config,\n        attn_implementation=\"eager\"  # Required: compiled attention breaks DataParallel\n    )\n    \n    # Layer freezing for efficiency\n    if config.freeze_layers:\n        # Freeze embeddings\n        if hasattr(model, 'model') and hasattr(model.model, 'embeddings'):\n            for param in model.model.embeddings.parameters():\n                param.requires_grad = False\n            print(\"  ✓ Froze embedding layer\")\n        elif hasattr(model, 'bert') and hasattr(model.bert, 'embeddings'):\n            for param in model.bert.embeddings.parameters():\n                param.requires_grad = False\n            print(\"  ✓ Froze embedding layer\")\n        \n        # Freeze bottom encoder layers\n        encoder_layers = None\n        if hasattr(model, 'model') and hasattr(model.model, 'encoder'):\n            encoder = model.model.encoder\n            if hasattr(encoder, 'layers'):\n                encoder_layers = encoder.layers\n            elif hasattr(encoder, 'layer'):\n                encoder_layers = encoder.layer\n        elif hasattr(model, 'bert') and hasattr(model.bert, 'encoder'):\n            encoder = model.bert.encoder\n            if hasattr(encoder, 'layer'):\n                encoder_layers = encoder.layer\n        \n        if encoder_layers is not None:\n            num_layers = len(encoder_layers)\n            num_freeze = int(num_layers * config.freeze_ratio)\n            for i, layer in enumerate(encoder_layers):\n                if i < num_freeze:\n                    for param in layer.parameters():\n                        param.requires_grad = False\n            print(f\"  ✓ Froze {num_freeze}/{num_layers} encoder layers\")\n        else:\n            print(\"  ⚠ Warning: Could not identify encoder layers for freezing\")\n    \n    total_params = sum(p.numel() for p in model.parameters())\n    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    frozen_params = total_params - trainable_params\n    \n    print(f\"\\n  Parameter Summary:\")\n    print(f\"    Total:     {total_params:>12,}\")\n    print(f\"    Trainable: {trainable_params:>12,} ({100*trainable_params/total_params:.1f}%)\")\n    print(f\"    Frozen:    {frozen_params:>12,} ({100*frozen_params/total_params:.1f}%)\")\n    \n    # Multi-GPU support with DataParallel\n    model.to(config.device)\n    if config.num_gpus > 1:\n        model = nn.DataParallel(model)\n        print(f\"\\n  ✓ DataParallel enabled across {config.num_gpus} GPUs\")\n    \n    return model\n\n\n# Initialize model\nmodel = get_model(config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T13:23:19.479814Z","iopub.execute_input":"2026-02-19T13:23:19.480027Z","iopub.status.idle":"2026-02-19T13:23:25.045008Z","shell.execute_reply.started":"2026-02-19T13:23:19.480007Z","shell.execute_reply":"2026-02-19T13:23:25.044170Z"}},"outputs":[{"name":"stdout","text":"\nLoading model: answerdotai/ModernBERT-large\n  Number of classes: 20\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.58G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a258525ecbe48b49288517a0391b8cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading weights:   0%|          | 0/172 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a30cf12d29e40bfab283f6c4d360ec9"}},"metadata":{}},{"name":"stderr","text":"\u001b[1mModernBertForSequenceClassification LOAD REPORT\u001b[0m from: answerdotai/ModernBERT-large\nKey               | Status     | \n------------------+------------+-\ndecoder.bias      | UNEXPECTED | \nclassifier.weight | MISSING    | \nclassifier.bias   | MISSING    | \n\n\u001b[3mNotes:\n- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"  ✓ Froze embedding layer\n  ⚠ Warning: Could not identify encoder layers for freezing\n\n  Parameter Summary:\n    Total:      395,851,796\n    Trainable:  344,273,940 (87.0%)\n    Frozen:      51,577,856 (13.0%)\n\n  ✓ DataParallel enabled across 2 GPUs\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## 6. Trainer","metadata":{}},{"cell_type":"code","source":"\nclass Trainer:\n    \n    def __init__(self, model, config, train_loader):\n        self.model = model\n        self.config = config\n        self.train_loader = train_loader\n        self.device = config.device\n\n        \n        # Access underlying model for parameter filtering (DataParallel wraps it)\n        base_model = model.module if hasattr(model, 'module') else model\n        \n        # Only optimize trainable parameters\n        self.optimizer = AdamW(\n            filter(lambda p: p.requires_grad, base_model.parameters()),\n            lr=config.learning_rate,\n            weight_decay=config.weight_decay\n        )\n        \n        # Total optimizer steps = one step per batch, per epoch\n        self.total_steps = len(train_loader) * config.num_epochs\n        self.warmup_steps = int(self.total_steps * config.warmup_ratio)\n        \n        self.scheduler = get_linear_schedule_with_warmup(\n            self.optimizer,\n            num_warmup_steps=self.warmup_steps,\n            num_training_steps=self.total_steps\n        )\n        \n        # Modern AMP API\n        self.scaler = GradScaler(\"cuda\") if config.use_fp16 else None\n        self.use_fp16 = config.use_fp16\n        \n        self.history = {'train_loss': [], 'learning_rate': []}\n        \n        print(f\"\\nTraining Configuration:\")\n        print(f\"  Device: {self.device} × {config.num_gpus} GPUs\")\n        print(f\"  Total optimizer steps: {self.total_steps}\")\n        print(f\"  Warmup steps: {self.warmup_steps}\")\n        print(f\"  Mixed precision (FP16): {self.use_fp16}\")\n    \n    def _get_trainable_params(self):\n        \"\"\"Get trainable parameters from model (handles DataParallel).\"\"\"\n        base_model = self.model.module if hasattr(self.model, 'module') else self.model\n        return filter(lambda p: p.requires_grad, base_model.parameters())\n    \n    def train_epoch(self, epoch):\n        \"\"\"Train for one epoch, stepping the optimizer on every batch.\"\"\"\n        self.model.train()\n        total_loss = 0\n        num_batches = 0\n        \n        progress_bar = tqdm(\n            self.train_loader,\n            desc=f\"Epoch {epoch+1}/{self.config.num_epochs}\",\n            leave=True\n        )\n        \n        for batch in progress_bar:\n            input_ids = batch['input_ids'].to(self.device)\n            attention_mask = batch['attention_mask'].to(self.device)\n            labels = batch['label'].to(self.device)\n            \n            self.optimizer.zero_grad()\n            \n            if self.use_fp16:\n                with autocast(\"cuda\"):\n                    outputs = self.model(\n                        input_ids=input_ids,\n                        attention_mask=attention_mask,\n                        labels=labels\n                    )\n                    # DataParallel returns averaged loss across GPUs\n                    loss = outputs.loss.mean()\n                \n                self.scaler.scale(loss).backward()\n                self.scaler.unscale_(self.optimizer)\n                torch.nn.utils.clip_grad_norm_(\n                    self._get_trainable_params(),\n                    self.config.max_grad_norm\n                )\n                self.scaler.step(self.optimizer)\n                self.scaler.update()\n            else:\n                outputs = self.model(\n                    input_ids=input_ids,\n                    attention_mask=attention_mask,\n                    labels=labels\n                )\n                loss = outputs.loss.mean()\n                loss.backward()\n                torch.nn.utils.clip_grad_norm_(\n                    self._get_trainable_params(),\n                    self.config.max_grad_norm\n                )\n                self.optimizer.step()\n            \n            self.scheduler.step()\n            \n            total_loss += loss.item()\n            num_batches += 1\n            \n            progress_bar.set_postfix({\n                'loss': f'{loss.item():.4f}',\n                'lr': f'{self.scheduler.get_last_lr()[0]:.2e}'\n            })\n        \n        return total_loss / num_batches\n    \n    def train(self):\n        \"\"\"Full training loop.\"\"\"\n        print(\"\\n\" + \"=\"*60)\n        print(\"Starting Training\")\n        print(\"=\"*60 + \"\\n\")\n        \n        start_time = time.time()\n        \n        for epoch in range(self.config.num_epochs):\n            epoch_start = time.time()\n            \n            train_loss = self.train_epoch(epoch)\n            self.history['train_loss'].append(train_loss)\n            \n            current_lr = self.scheduler.get_last_lr()[0]\n            self.history['learning_rate'].append(current_lr)\n            \n            epoch_time = time.time() - epoch_start\n            \n            print(f\"\\nEpoch {epoch+1}/{self.config.num_epochs} - \"\n                  f\"Train Loss: {train_loss:.4f} - \"\n                  f\"LR: {current_lr:.2e} - \"\n                  f\"Time: {epoch_time:.1f}s\")\n            \n            # Memory report\n            if torch.cuda.is_available():\n                for i in range(config.num_gpus):\n                    allocated = torch.cuda.memory_allocated(i) / 1024**3\n                    reserved = torch.cuda.memory_reserved(i) / 1024**3\n                    print(f\"  GPU {i} memory: {allocated:.1f} GB allocated, {reserved:.1f} GB reserved\")\n        \n        total_time = time.time() - start_time\n        print(f\"\\nTraining Complete! Total time: {total_time/60:.1f} minutes\")\n        \n        return self.history","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T13:23:25.046072Z","iopub.execute_input":"2026-02-19T13:23:25.046337Z","iopub.status.idle":"2026-02-19T13:23:25.061259Z","shell.execute_reply.started":"2026-02-19T13:23:25.046311Z","shell.execute_reply":"2026-02-19T13:23:25.060551Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## 8. Train the Model","metadata":{}},{"cell_type":"code","source":"\n\n# Set random seed for reproducibility\ndef set_seed(seed: int):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\nset_seed(config.seed)\n\n# Initialize trainer and train\ntrainer = Trainer(model, config, train_loader)\nhistory = trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T13:23:25.062392Z","iopub.execute_input":"2026-02-19T13:23:25.062774Z","iopub.status.idle":"2026-02-19T13:53:01.332084Z","shell.execute_reply.started":"2026-02-19T13:23:25.062747Z","shell.execute_reply":"2026-02-19T13:53:01.331368Z"}},"outputs":[{"name":"stdout","text":"\nTraining Configuration:\n  Device: cuda × 2 GPUs\n  Total optimizer steps: 1412\n  Warmup steps: 141\n  Mixed precision (FP16): True\n\n============================================================\nStarting Training\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/4:   0%|          | 0/353 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nEpoch 1/4: 100%|██████████| 353/353 [07:24<00:00,  1.26s/it, loss=0.9025, lr=2.50e-05]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/4 - Train Loss: 1.4021 - LR: 2.50e-05 - Time: 444.1s\n  GPU 0 memory: 5.3 GB allocated, 12.9 GB reserved\n  GPU 1 memory: 0.0 GB allocated, 9.7 GB reserved\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/4: 100%|██████████| 353/353 [07:26<00:00,  1.26s/it, loss=0.3550, lr=1.67e-05]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2/4 - Train Loss: 0.5473 - LR: 1.67e-05 - Time: 446.4s\n  GPU 0 memory: 5.3 GB allocated, 12.9 GB reserved\n  GPU 1 memory: 0.0 GB allocated, 9.7 GB reserved\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/4: 100%|██████████| 353/353 [07:23<00:00,  1.26s/it, loss=0.3829, lr=8.33e-06]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3/4 - Train Loss: 0.2003 - LR: 8.33e-06 - Time: 443.6s\n  GPU 0 memory: 5.3 GB allocated, 12.9 GB reserved\n  GPU 1 memory: 0.0 GB allocated, 9.7 GB reserved\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/4: 100%|██████████| 353/353 [07:22<00:00,  1.25s/it, loss=0.0056, lr=0.00e+00]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4/4 - Train Loss: 0.0930 - LR: 0.00e+00 - Time: 442.1s\n  GPU 0 memory: 5.3 GB allocated, 12.9 GB reserved\n  GPU 1 memory: 0.0 GB allocated, 9.7 GB reserved\n\nTraining Complete! Total time: 29.6 minutes\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## 9. Evaluation","metadata":{}},{"cell_type":"code","source":"\n@torch.no_grad()\ndef evaluate(model, test_loader, config):\n    \"\"\"Comprehensive evaluation on test set.\"\"\"\n    print(\"\\n\" + \"=\"*60)\n    print(\"Evaluating on Test Set\")\n    print(\"=\"*60 + \"\\n\")\n    \n    model.eval()\n    \n    all_predictions = []\n    all_labels = []\n    total_loss = 0\n    \n    for batch in tqdm(test_loader, desc=\"Evaluating\"):\n        input_ids = batch['input_ids'].to(config.device)\n        attention_mask = batch['attention_mask'].to(config.device)\n        labels = batch['label'].to(config.device)\n        \n        if config.use_fp16:\n            with autocast(\"cuda\"):\n                outputs = model(\n                    input_ids=input_ids,\n                    attention_mask=attention_mask,\n                    labels=labels\n                )\n        else:\n            outputs = model(\n                input_ids=input_ids,\n                attention_mask=attention_mask,\n                labels=labels\n            )\n        \n        # Handle DataParallel loss\n        loss = outputs.loss.mean() if outputs.loss.dim() > 0 else outputs.loss\n        total_loss += loss.item()\n        predictions = torch.argmax(outputs.logits, dim=-1)\n        \n        all_predictions.extend(predictions.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n    \n    all_predictions = np.array(all_predictions)\n    all_labels = np.array(all_labels)\n    \n    # Calculate metrics\n    accuracy = accuracy_score(all_labels, all_predictions)\n    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n        all_labels, all_predictions, average='macro'\n    )\n    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n        all_labels, all_predictions, average='weighted'\n    )\n    avg_loss = total_loss / len(test_loader)\n    \n    label_names = get_label_names()\n    report = classification_report(all_labels, all_predictions, target_names=label_names, digits=4)\n    conf_matrix = confusion_matrix(all_labels, all_predictions)\n    \n    # Print results\n    print(\"\\n\" + \"=\"*60)\n    print(\"EVALUATION RESULTS\")\n    print(\"=\"*60)\n    print(f\"\\n[Overall Metrics]\")\n    print(f\"  Test Loss: {avg_loss:.4f}\")\n    print(f\"  Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n    print(f\"\\n[Macro Averages]\")\n    print(f\"  Precision: {precision_macro:.4f}\")\n    print(f\"  Recall: {recall_macro:.4f}\")\n    print(f\"  F1 Score: {f1_macro:.4f}\")\n    print(f\"\\n[Weighted Averages]\")\n    print(f\"  Precision: {precision_weighted:.4f}\")\n    print(f\"  Recall: {recall_weighted:.4f}\")\n    print(f\"  F1 Score: {f1_weighted:.4f}\")\n    print(\"\\n\" + \"=\"*60)\n    print(\"CLASSIFICATION REPORT (Per-Class)\")\n    print(\"=\"*60)\n    print(report)\n    \n    return {\n        'test_loss': avg_loss,\n        'accuracy': accuracy,\n        'precision_macro': precision_macro,\n        'recall_macro': recall_macro,\n        'f1_macro': f1_macro,\n        'precision_weighted': precision_weighted,\n        'recall_weighted': recall_weighted,\n        'f1_weighted': f1_weighted,\n        'classification_report': report,\n        'confusion_matrix': conf_matrix,\n        'predictions': all_predictions,\n        'labels': all_labels,\n        'label_names': label_names\n    }\n\n\n# Evaluate\nresults = evaluate(model, test_loader, config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T13:53:01.333145Z","iopub.execute_input":"2026-02-19T13:53:01.333397Z","iopub.status.idle":"2026-02-19T13:54:52.378451Z","shell.execute_reply.started":"2026-02-19T13:53:01.333372Z","shell.execute_reply":"2026-02-19T13:54:52.377676Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nEvaluating on Test Set\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 236/236 [01:51<00:00,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nEVALUATION RESULTS\n============================================================\n\n[Overall Metrics]\n  Test Loss: 1.3527\n  Accuracy: 0.7420 (74.20%)\n\n[Macro Averages]\n  Precision: 0.7386\n  Recall: 0.7317\n  F1 Score: 0.7332\n\n[Weighted Averages]\n  Precision: 0.7489\n  Recall: 0.7420\n  F1 Score: 0.7435\n\n============================================================\nCLASSIFICATION REPORT (Per-Class)\n============================================================\n                          precision    recall  f1-score   support\n\n             alt.atheism     0.6097    0.5141    0.5578       319\n           comp.graphics     0.7282    0.7712    0.7491       389\n comp.os.ms-windows.misc     0.6967    0.6878    0.6922       394\ncomp.sys.ibm.pc.hardware     0.6822    0.7117    0.6966       392\n   comp.sys.mac.hardware     0.7737    0.7195    0.7456       385\n          comp.windows.x     0.8652    0.7797    0.8202       395\n            misc.forsale     0.8354    0.8718    0.8532       390\n               rec.autos     0.6000    0.7803    0.6784       396\n         rec.motorcycles     0.7933    0.7714    0.7822       398\n      rec.sport.baseball     0.8243    0.8388    0.8315       397\n        rec.sport.hockey     0.8934    0.8822    0.8878       399\n               sci.crypt     0.8614    0.7222    0.7857       396\n         sci.electronics     0.6970    0.7023    0.6996       393\n                 sci.med     0.9068    0.8359    0.8699       396\n               sci.space     0.7847    0.8046    0.7945       394\n  soc.religion.christian     0.8154    0.7990    0.8071       398\n      talk.politics.guns     0.5789    0.6951    0.6317       364\n   talk.politics.mideast     0.8646    0.7979    0.8299       376\n      talk.politics.misc     0.5735    0.5032    0.5361       310\n      talk.religion.misc     0.3875    0.4462    0.4148       251\n\n                accuracy                         0.7420      7532\n               macro avg     0.7386    0.7317    0.7332      7532\n            weighted avg     0.7489    0.7420    0.7435      7532\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"## 10. Final Summary","metadata":{}},{"cell_type":"code","source":"\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"FINAL RESULTS SUMMARY\")\nprint(\"=\"*70)\nprint(f\"  Model: {config.model_name}\")\nprint(f\"  GPUs: {config.num_gpus} × T4\")\nprint(f\"  Test Accuracy: {results['accuracy']:.4f} ({results['accuracy']*100:.2f}%)\")\nprint(f\"  Macro F1 Score: {results['f1_macro']:.4f}\")\nprint(f\"  Weighted F1 Score: {results['f1_weighted']:.4f}\")\nprint(\"=\"*70)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T13:54:52.379389Z","iopub.execute_input":"2026-02-19T13:54:52.379686Z","iopub.status.idle":"2026-02-19T13:54:52.384874Z","shell.execute_reply.started":"2026-02-19T13:54:52.379659Z","shell.execute_reply":"2026-02-19T13:54:52.384319Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nFINAL RESULTS SUMMARY\n======================================================================\n  Model: answerdotai/ModernBERT-large\n  GPUs: 2 × T4\n  Test Accuracy: 0.7420 (74.20%)\n  Macro F1 Score: 0.7332\n  Weighted F1 Score: 0.7435\n======================================================================\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## 11. Save Model","metadata":{}},{"cell_type":"code","source":"\n\nif config.save_model:\n    os.makedirs(config.output_dir, exist_ok=True)\n    \n    # Unwrap DataParallel if needed\n    save_model = model.module if hasattr(model, 'module') else model\n    \n    # Save model\n    model_path = os.path.join(config.output_dir, \"model\")\n    save_model.save_pretrained(model_path)\n    print(f\"Model saved to: {model_path}\")\n    \n    # Save tokenizer\n    tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n    tokenizer.save_pretrained(model_path)\n    print(f\"Tokenizer saved to: {model_path}\")\n    \n    # Save training history\n    history_path = os.path.join(config.output_dir, \"training_history.json\")\n    with open(history_path, 'w') as f:\n        json.dump(history, f, indent=2)\n    print(f\"Training history saved to: {history_path}\")\n    \n    # Save evaluation metrics\n    metrics = {\n        'model': config.model_name,\n        'num_gpus': config.num_gpus,\n        'test_loss': results['test_loss'],\n        'accuracy': results['accuracy'],\n        'precision_macro': results['precision_macro'],\n        'recall_macro': results['recall_macro'],\n        'f1_macro': results['f1_macro'],\n        'precision_weighted': results['precision_weighted'],\n        'recall_weighted': results['recall_weighted'],\n        'f1_weighted': results['f1_weighted'],\n    }\n    metrics_path = os.path.join(config.output_dir, \"evaluation_metrics.json\")\n    with open(metrics_path, 'w') as f:\n        json.dump(metrics, f, indent=2)\n    print(f\"Evaluation metrics saved to: {metrics_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T13:54:52.386601Z","iopub.execute_input":"2026-02-19T13:54:52.386809Z","iopub.status.idle":"2026-02-19T13:54:55.881268Z","shell.execute_reply.started":"2026-02-19T13:54:52.386790Z","shell.execute_reply":"2026-02-19T13:54:55.880469Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ded774fac454785bdcbace33dbff3c5"}},"metadata":{}},{"name":"stdout","text":"Model saved to: ./output/model\nTokenizer saved to: ./output/model\nTraining history saved to: ./output/training_history.json\nEvaluation metrics saved to: ./output/evaluation_metrics.json\n","output_type":"stream"}],"execution_count":10}]}