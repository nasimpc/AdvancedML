{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!/usr/bin/env python\n",
    "coding: utf-8\n",
    "\n",
    "# ModernBERT-Large Fine-tuning for 20 Newsgroups Text Classification\n",
    "\n",
    "An implementation of ModernBERT-large fine-tuning for multi-class text classification\n",
    "using the 20 newsgroups dataset, optimized for Kaggle T4 x2 GPUs (2 \u00d7 16 GB VRAM).\n",
    "\n",
    "## 1. Design Decisions\n",
    "\n",
    "| Parameter | Value | Justification |\n",
    "|-----------|-------|---------------|\n",
    "| **Model** | answerdotai/ModernBERT-large | 395M params, 28 layers, RoPE, 8192 context |\n",
    "| **Learning Rate** | 3e-5 | Lower than base for stability with large model |\n",
    "| **Batch Size** | 16 per GPU \u00d7 2 GPUs = 32 | Fits T4 16GB with FP16 at seq len 256 |\n",
    "| **Gradient Accum** | 2 | Effective batch size 64 |\n",
    "| **Epochs** | 4 | Large model benefits from more epochs |\n",
    "| **Max Length** | 256 | Good coverage of newsgroup posts |\n",
    "| **Multi-GPU** | DataParallel on 2 T4s | Near-linear speedup |\n",
    "| **Layer Freezing** | Bottom 50% (14/28 layers) | Saves memory on T4 |\n",
    "\n",
    "## 2. Imports & Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"  # Prevent fork warnings with DataLoader\n",
    "\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "from typing import Tuple\n",
    "from dataclasses import dataclass, field\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.amp import GradScaler, autocast\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoConfig,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of GPUs: {num_gpus}\")\n",
    "    for i in range(num_gpus):\n",
    "        print(f\"  GPU {i}: {torch.cuda.get_device_name(i)} \"\n",
    "              f\"({torch.cuda.get_device_properties(i).total_memory / 1024**3:.1f} GB)\")\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "Configuration for ModernBERT-Large Fine-tuning on 20 Newsgroups\n",
    "(Optimized for Kaggle T4 x2 \u2014 2 \u00d7 16 GB VRAM)\n",
    "\n",
    "Design Decisions:\n",
    "-----------------\n",
    "1. Model: answerdotai/ModernBERT-large\n",
    "   - 395M parameters, 28 encoder layers\n",
    "   - Modern bidirectional encoder pre-trained on 2 trillion tokens\n",
    "   - Uses RoPE and alternating local-global attention\n",
    "   \n",
    "2. Learning Rate: 3e-5\n",
    "   - Slightly lower than base model for training stability\n",
    "   - Larger models are more sensitive to high LR\n",
    "   \n",
    "3. Batch Size: 16 per GPU (32 total across 2 T4s)\n",
    "   - With gradient accumulation of 2, effective batch = 64\n",
    "   - Fits comfortably in T4 16GB with FP16 + layer freezing\n",
    "   \n",
    "4. Epochs: 4\n",
    "   - Large model with frozen layers benefits from more training\n",
    "\n",
    "5. Layer Freezing: Bottom 50% (14/28 encoder layers)\n",
    "   - Critical for fitting 395M model on T4 GPUs\n",
    "   - Lower layers capture universal language features\n",
    "\n",
    "6. Multi-GPU: DataParallel\n",
    "   - Automatically splits batches across 2 T4 GPUs\n",
    "   - Simple, no code changes needed for the training loop\n",
    "\"\"\"\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Configuration class with all hyperparameters and settings.\"\"\"\n",
    "    \n",
    "    # Model Configuration\n",
    "    model_name: str = \"answerdotai/ModernBERT-large\"\n",
    "    num_labels: int = 20\n",
    "    \n",
    "    # Training Hyperparameters\n",
    "    learning_rate: float = 3e-5\n",
    "    batch_size: int = 8  # Per-GPU batch size (total = batch_size \u00d7 num_gpus)\n",
    "    num_epochs: int = 4\n",
    "    warmup_ratio: float = 0.1\n",
    "    weight_decay: float = 0.01\n",
    "    max_grad_norm: float = 1.0\n",
    "    gradient_accumulation_steps: int = 4  # Effective batch = 8 \u00d7 2 GPUs \u00d7 4 = 64\n",
    "    \n",
    "    # Layer Freezing\n",
    "    freeze_layers: bool = True\n",
    "    freeze_ratio: float = 0.5  # Freeze bottom 50% of encoder layers (14/28)\n",
    "    \n",
    "    # Data Configuration\n",
    "    dataset_name: str = \"SetFit/20_newsgroups\"\n",
    "    max_length: int = 512  # 91% token coverage (vs 76% at 256)\n",
    "    \n",
    "    # Training Settings\n",
    "    seed: int = 42\n",
    "    use_fp16: bool = True\n",
    "    save_model: bool = True\n",
    "    output_dir: str = \"./output\"\n",
    "    \n",
    "    # Device (auto-detected)\n",
    "    device: str = field(default_factory=lambda: \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    num_gpus: int = field(default_factory=lambda: torch.cuda.device_count() if torch.cuda.is_available() else 0)\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.device == \"cpu\":\n",
    "            self.use_fp16 = False\n",
    "        # Scale batch size across GPUs\n",
    "        self.total_batch_size = self.batch_size * max(1, self.num_gpus)\n",
    "        self.effective_batch_size = self.total_batch_size * self.gradient_accumulation_steps\n",
    "            \n",
    "    def to_dict(self) -> dict:\n",
    "        return {\n",
    "            \"model_name\": self.model_name,\n",
    "            \"num_labels\": self.num_labels,\n",
    "            \"learning_rate\": self.learning_rate,\n",
    "            \"batch_size_per_gpu\": self.batch_size,\n",
    "            \"num_gpus\": self.num_gpus,\n",
    "            \"total_batch_size\": self.total_batch_size,\n",
    "            \"effective_batch_size\": self.effective_batch_size,\n",
    "            \"num_epochs\": self.num_epochs,\n",
    "            \"warmup_ratio\": self.warmup_ratio,\n",
    "            \"weight_decay\": self.weight_decay,\n",
    "            \"gradient_accumulation_steps\": self.gradient_accumulation_steps,\n",
    "            \"max_length\": self.max_length,\n",
    "            \"freeze_layers\": self.freeze_layers,\n",
    "            \"freeze_ratio\": self.freeze_ratio,\n",
    "            \"seed\": self.seed,\n",
    "            \"use_fp16\": self.use_fp16,\n",
    "            \"device\": self.device,\n",
    "        }\n",
    "\n",
    "# Initialize configuration\n",
    "config = Config()\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for key, value in config.to_dict().items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dataset Exploration & Statistical Overview\n",
    "\n",
    "View the dataset structure, class distribution, and text length statistics\n",
    "before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "Dataset Exploration for 20 Newsgroups\n",
    "\n",
    "Shows:\n",
    "- Dataset structure and splits\n",
    "- Class distribution (train & test)\n",
    "- Text length statistics (chars, words, tokens)\n",
    "- Sample documents from each class\n",
    "\"\"\"\n",
    "\n",
    "def explore_dataset(config):\n",
    "    \"\"\"Load and display comprehensive dataset statistics.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"DATASET EXPLORATION: 20 Newsgroups\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Load raw dataset\n",
    "    dataset = load_dataset(config.dataset_name)\n",
    "    train_data = dataset['train']\n",
    "    test_data = dataset['test']\n",
    "    \n",
    "    label_names = [\n",
    "        'alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc',\n",
    "        'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x',\n",
    "        'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball',\n",
    "        'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med',\n",
    "        'sci.space', 'soc.religion.christian', 'talk.politics.guns',\n",
    "        'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc'\n",
    "    ]\n",
    "    \n",
    "    # --- Basic Info ---\n",
    "    print(f\"\\n{'\u2500'*50}\")\n",
    "    print(f\"  Dataset: {config.dataset_name}\")\n",
    "    print(f\"  Number of classes: {len(label_names)}\")\n",
    "    print(f\"  Train samples: {len(train_data):,}\")\n",
    "    print(f\"  Test samples:  {len(test_data):,}\")\n",
    "    print(f\"  Total samples: {len(train_data) + len(test_data):,}\")\n",
    "    print(f\"  Features: {list(train_data.features.keys())}\")\n",
    "    print(f\"{'\u2500'*50}\")\n",
    "    \n",
    "    # --- Class Distribution ---\n",
    "    print(f\"\\n{'\u2500'*50}\")\n",
    "    print(\"  CLASS DISTRIBUTION\")\n",
    "    print(f\"{'\u2500'*50}\")\n",
    "    \n",
    "    train_labels = train_data['label']\n",
    "    test_labels = test_data['label']\n",
    "    train_counts = Counter(train_labels)\n",
    "    test_counts = Counter(test_labels)\n",
    "    \n",
    "    print(f\"\\n  {'Category':<35} {'Train':>6} {'Test':>6} {'Total':>6}\")\n",
    "    print(f\"  {'\u2500'*55}\")\n",
    "    for i, name in enumerate(label_names):\n",
    "        tr = train_counts.get(i, 0)\n",
    "        te = test_counts.get(i, 0)\n",
    "        bar = '\u2588' * (tr // 20)\n",
    "        print(f\"  {name:<35} {tr:>6} {te:>6} {tr+te:>6}  {bar}\")\n",
    "    \n",
    "    print(f\"  {'\u2500'*55}\")\n",
    "    print(f\"  {'TOTAL':<35} {len(train_data):>6} {len(test_data):>6} {len(train_data)+len(test_data):>6}\")\n",
    "    \n",
    "    # Class balance metrics\n",
    "    train_counts_list = [train_counts.get(i, 0) for i in range(len(label_names))]\n",
    "    print(f\"\\n  Train class balance:\")\n",
    "    print(f\"    Min samples/class: {min(train_counts_list)}\")\n",
    "    print(f\"    Max samples/class: {max(train_counts_list)}\")\n",
    "    print(f\"    Mean samples/class: {np.mean(train_counts_list):.1f}\")\n",
    "    print(f\"    Std samples/class: {np.std(train_counts_list):.1f}\")\n",
    "    print(f\"    Imbalance ratio (max/min): {max(train_counts_list)/max(min(train_counts_list),1):.2f}\")\n",
    "    \n",
    "    # --- Text Length Statistics ---\n",
    "    print(f\"\\n{'\u2500'*50}\")\n",
    "    print(\"  TEXT LENGTH STATISTICS (Training Set)\")\n",
    "    print(f\"{'\u2500'*50}\")\n",
    "    \n",
    "    texts = train_data['text']\n",
    "    char_lengths = [len(t) for t in texts]\n",
    "    word_lengths = [len(t.split()) for t in texts]\n",
    "    \n",
    "    for metric_name, lengths in [(\"Character lengths\", char_lengths), (\"Word counts\", word_lengths)]:\n",
    "        arr = np.array(lengths)\n",
    "        print(f\"\\n  {metric_name}:\")\n",
    "        print(f\"    Min:    {arr.min():>8,}\")\n",
    "        print(f\"    Max:    {arr.max():>8,}\")\n",
    "        print(f\"    Mean:   {arr.mean():>8,.1f}\")\n",
    "        print(f\"    Median: {np.median(arr):>8,.1f}\")\n",
    "        print(f\"    Std:    {arr.std():>8,.1f}\")\n",
    "        print(f\"    P25:    {np.percentile(arr, 25):>8,.1f}\")\n",
    "        print(f\"    P75:    {np.percentile(arr, 75):>8,.1f}\")\n",
    "        print(f\"    P95:    {np.percentile(arr, 95):>8,.1f}\")\n",
    "    \n",
    "    # Token-level stats with tokenizer\n",
    "    print(f\"\\n  Tokenized lengths (using {config.model_name} tokenizer):\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "    \n",
    "    # Sample for speed (full tokenization on large dataset is slow)\n",
    "    sample_size = min(2000, len(texts))\n",
    "    sample_texts = random.sample(texts, sample_size)\n",
    "    token_lengths = [len(tokenizer.encode(t)) for t in sample_texts]\n",
    "    arr = np.array(token_lengths)\n",
    "    \n",
    "    print(f\"    (Sampled {sample_size:,} documents)\")\n",
    "    print(f\"    Min:    {arr.min():>8,}\")\n",
    "    print(f\"    Max:    {arr.max():>8,}\")\n",
    "    print(f\"    Mean:   {arr.mean():>8,.1f}\")\n",
    "    print(f\"    Median: {np.median(arr):>8,.1f}\")\n",
    "    print(f\"    P95:    {np.percentile(arr, 95):>8,.1f}\")\n",
    "    \n",
    "    # Coverage at different max_length thresholds\n",
    "    print(f\"\\n  Token coverage at different max_length:\")\n",
    "    for ml in [128, 256, 512]:\n",
    "        coverage = (arr <= ml).sum() / len(arr) * 100\n",
    "        print(f\"    max_length={ml}: {coverage:.1f}% of documents fully covered\")\n",
    "    print(f\"    \u2192 Using max_length={config.max_length}\")\n",
    "    \n",
    "    # --- Sample Documents ---\n",
    "    print(f\"\\n{'\u2500'*50}\")\n",
    "    print(\"  SAMPLE DOCUMENTS (first 200 chars)\")\n",
    "    print(f\"{'\u2500'*50}\")\n",
    "    \n",
    "    # Show 1 sample per first 5 classes\n",
    "    for i in range(min(5, len(label_names))):\n",
    "        # Find first document with this label\n",
    "        for j, lbl in enumerate(train_labels):\n",
    "            if lbl == i:\n",
    "                text_preview = texts[j][:200].replace('\\n', ' ')\n",
    "                print(f\"\\n  [{label_names[i]}]\")\n",
    "                print(f\"  \\\"{text_preview}...\\\"\")\n",
    "                break\n",
    "    \n",
    "    print(f\"\\n{'\u2500'*50}\")\n",
    "    print(f\"  (Showing 5 of {len(label_names)} classes)\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "# Run dataset exploration\n",
    "dataset = explore_dataset(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Loading & Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "Data Loading and Preprocessing for 20 Newsgroups\n",
    "\n",
    "Design Decisions:\n",
    "-----------------\n",
    "1. Tokenization: ModernBERT-large tokenizer\n",
    "2. Padding: max_length for uniform batch shapes (better for DataParallel)\n",
    "3. DataLoader: 4 workers per GPU, pin memory\n",
    "\"\"\"\n",
    "\n",
    "def get_label_names() -> list:\n",
    "    \"\"\"Get the 20 newsgroup category names.\"\"\"\n",
    "    return [\n",
    "        'alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc',\n",
    "        'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x',\n",
    "        'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball',\n",
    "        'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med',\n",
    "        'sci.space', 'soc.religion.christian', 'talk.politics.guns',\n",
    "        'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc'\n",
    "    ]\n",
    "\n",
    "\n",
    "def load_and_prepare_data(config, dataset=None) -> Tuple[DataLoader, DataLoader]:\n",
    "    \"\"\"Load 20 newsgroups dataset, tokenize, and create DataLoaders.\"\"\"\n",
    "    print(f\"\\nPreparing data for training...\")\n",
    "    \n",
    "    # Use pre-loaded dataset if available (from exploration step)\n",
    "    if dataset is None:\n",
    "        dataset = load_dataset(config.dataset_name)\n",
    "    \n",
    "    train_dataset = dataset['train']\n",
    "    test_dataset = dataset['test']\n",
    "    \n",
    "    print(f\"  Train size: {len(train_dataset)}\")\n",
    "    print(f\"  Test size: {len(test_dataset)}\")\n",
    "    \n",
    "    # Initialize tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "    \n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(\n",
    "            examples['text'],\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=config.max_length,\n",
    "            return_tensors=None\n",
    "        )\n",
    "    \n",
    "    # Apply tokenization\n",
    "    print(\"  Tokenizing datasets...\")\n",
    "    train_dataset = train_dataset.map(tokenize_function, batched=True, desc=\"Tokenizing train\")\n",
    "    test_dataset = test_dataset.map(tokenize_function, batched=True, desc=\"Tokenizing test\")\n",
    "    \n",
    "    # Set format for PyTorch\n",
    "    columns = ['input_ids', 'attention_mask', 'label']\n",
    "    train_dataset.set_format(type='torch', columns=columns)\n",
    "    test_dataset.set_format(type='torch', columns=columns)\n",
    "    \n",
    "    # DataLoader config \u2014 use total_batch_size (accounts for multi-GPU)\n",
    "    num_workers = 4 if config.device == 'cuda' else 0\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config.total_batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True if config.device == 'cuda' else False,\n",
    "        drop_last=True  # Avoids uneven batch splits across GPUs\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=config.total_batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True if config.device == 'cuda' else False\n",
    "    )\n",
    "    \n",
    "    print(f\"  DataLoaders ready \u2014 Train batches: {len(train_loader)}, Test batches: {len(test_loader)}\")\n",
    "    print(f\"  Batch size per GPU: {config.batch_size}, Total batch: {config.total_batch_size}, \"\n",
    "          f\"Effective: {config.effective_batch_size}\")\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "# Load data (reuses the dataset from exploration to avoid re-downloading)\n",
    "train_loader, test_loader = load_and_prepare_data(config, dataset=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model\n",
    "\n",
    "Initialize ModernBERT-large with classification head, layer freezing, and multi-GPU support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "ModernBERT-Large Model for Text Classification\n",
    "\n",
    "Design Decisions:\n",
    "-----------------\n",
    "1. Architecture: ModernBERT-large (395M params) + classification head\n",
    "2. Layer Freezing: Freeze embeddings + bottom 14/28 encoder layers\n",
    "3. Multi-GPU: Wrap with DataParallel for dual T4s\n",
    "\"\"\"\n",
    "\n",
    "def get_model(config):\n",
    "    \"\"\"Initialize ModernBERT-large with layer freezing and optional DataParallel.\"\"\"\n",
    "    print(f\"\\nLoading model: {config.model_name}\")\n",
    "    print(f\"  Number of classes: {config.num_labels}\")\n",
    "    \n",
    "    model_config = AutoConfig.from_pretrained(\n",
    "        config.model_name,\n",
    "        num_labels=config.num_labels,\n",
    "        finetuning_task=\"text-classification\"\n",
    "    )\n",
    "    \n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        config.model_name,\n",
    "        config=model_config\n",
    "    )\n",
    "    \n",
    "    # Layer freezing for efficiency\n",
    "    if config.freeze_layers:\n",
    "        # Freeze embeddings\n",
    "        if hasattr(model, 'model') and hasattr(model.model, 'embeddings'):\n",
    "            for param in model.model.embeddings.parameters():\n",
    "                param.requires_grad = False\n",
    "            print(\"  \u2713 Froze embedding layer\")\n",
    "        elif hasattr(model, 'bert') and hasattr(model.bert, 'embeddings'):\n",
    "            for param in model.bert.embeddings.parameters():\n",
    "                param.requires_grad = False\n",
    "            print(\"  \u2713 Froze embedding layer\")\n",
    "        \n",
    "        # Freeze bottom encoder layers\n",
    "        encoder_layers = None\n",
    "        if hasattr(model, 'model') and hasattr(model.model, 'encoder'):\n",
    "            encoder = model.model.encoder\n",
    "            if hasattr(encoder, 'layers'):\n",
    "                encoder_layers = encoder.layers\n",
    "            elif hasattr(encoder, 'layer'):\n",
    "                encoder_layers = encoder.layer\n",
    "        elif hasattr(model, 'bert') and hasattr(model.bert, 'encoder'):\n",
    "            encoder = model.bert.encoder\n",
    "            if hasattr(encoder, 'layer'):\n",
    "                encoder_layers = encoder.layer\n",
    "        \n",
    "        if encoder_layers is not None:\n",
    "            num_layers = len(encoder_layers)\n",
    "            num_freeze = int(num_layers * config.freeze_ratio)\n",
    "            for i, layer in enumerate(encoder_layers):\n",
    "                if i < num_freeze:\n",
    "                    for param in layer.parameters():\n",
    "                        param.requires_grad = False\n",
    "            print(f\"  \u2713 Froze {num_freeze}/{num_layers} encoder layers\")\n",
    "        else:\n",
    "            print(\"  \u26a0 Warning: Could not identify encoder layers for freezing\")\n",
    "    \n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    frozen_params = total_params - trainable_params\n",
    "    \n",
    "    print(f\"\\n  Parameter Summary:\")\n",
    "    print(f\"    Total:     {total_params:>12,}\")\n",
    "    print(f\"    Trainable: {trainable_params:>12,} ({100*trainable_params/total_params:.1f}%)\")\n",
    "    print(f\"    Frozen:    {frozen_params:>12,} ({100*frozen_params/total_params:.1f}%)\")\n",
    "    \n",
    "    # Multi-GPU support with DataParallel\n",
    "    model.to(config.device)\n",
    "    if config.num_gpus > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "        print(f\"\\n  \u2713 DataParallel enabled across {config.num_gpus} GPUs\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "model = get_model(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Trainer\n",
    "\n",
    "Training loop with AdamW, warmup scheduler, gradient accumulation, FP16, and multi-GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "Training Module for ModernBERT-Large Fine-tuning (Dual T4 Optimized)\n",
    "\n",
    "Key features:\n",
    "- DataParallel multi-GPU support\n",
    "- Gradient accumulation (effective batch 64)\n",
    "- FP16 mixed precision via torch.amp\n",
    "- Linear warmup + decay scheduler\n",
    "\"\"\"\n",
    "\n",
    "class Trainer:\n",
    "    \"\"\"Trainer class for ModernBERT-large fine-tuning on dual T4 GPUs.\"\"\"\n",
    "    \n",
    "    def __init__(self, model, config, train_loader):\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        self.train_loader = train_loader\n",
    "        self.device = config.device\n",
    "        self.grad_accum_steps = config.gradient_accumulation_steps\n",
    "        \n",
    "        # Access underlying model for parameter filtering (DataParallel wraps it)\n",
    "        base_model = model.module if hasattr(model, 'module') else model\n",
    "        \n",
    "        # Only optimize trainable parameters\n",
    "        self.optimizer = AdamW(\n",
    "            filter(lambda p: p.requires_grad, base_model.parameters()),\n",
    "            lr=config.learning_rate,\n",
    "            weight_decay=config.weight_decay\n",
    "        )\n",
    "        \n",
    "        # Total optimizer steps accounts for gradient accumulation\n",
    "        self.total_steps = (len(train_loader) // self.grad_accum_steps) * config.num_epochs\n",
    "        self.warmup_steps = int(self.total_steps * config.warmup_ratio)\n",
    "        \n",
    "        self.scheduler = get_linear_schedule_with_warmup(\n",
    "            self.optimizer,\n",
    "            num_warmup_steps=self.warmup_steps,\n",
    "            num_training_steps=self.total_steps\n",
    "        )\n",
    "        \n",
    "        # Modern AMP API\n",
    "        self.scaler = GradScaler(\"cuda\") if config.use_fp16 else None\n",
    "        self.use_fp16 = config.use_fp16\n",
    "        \n",
    "        self.history = {'train_loss': [], 'learning_rate': []}\n",
    "        \n",
    "        print(f\"\\nTraining Configuration:\")\n",
    "        print(f\"  Device: {self.device} \u00d7 {config.num_gpus} GPUs\")\n",
    "        print(f\"  Total optimizer steps: {self.total_steps}\")\n",
    "        print(f\"  Warmup steps: {self.warmup_steps}\")\n",
    "        print(f\"  Gradient accumulation: {self.grad_accum_steps}\")\n",
    "        print(f\"  Effective batch size: {config.effective_batch_size}\")\n",
    "        print(f\"  Mixed precision (FP16): {self.use_fp16}\")\n",
    "    \n",
    "    def _get_trainable_params(self):\n",
    "        \"\"\"Get trainable parameters from model (handles DataParallel).\"\"\"\n",
    "        base_model = self.model.module if hasattr(self.model, 'module') else self.model\n",
    "        return filter(lambda p: p.requires_grad, base_model.parameters())\n",
    "    \n",
    "    def train_epoch(self, epoch):\n",
    "        \"\"\"Train for one epoch with gradient accumulation.\"\"\"\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        progress_bar = tqdm(\n",
    "            self.train_loader,\n",
    "            desc=f\"Epoch {epoch+1}/{self.config.num_epochs}\",\n",
    "            leave=True\n",
    "        )\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        for step, batch in enumerate(progress_bar):\n",
    "            input_ids = batch['input_ids'].to(self.device)\n",
    "            attention_mask = batch['attention_mask'].to(self.device)\n",
    "            labels = batch['label'].to(self.device)\n",
    "            \n",
    "            if self.use_fp16:\n",
    "                with autocast(\"cuda\"):\n",
    "                    outputs = self.model(\n",
    "                        input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        labels=labels\n",
    "                    )\n",
    "                    # DataParallel returns averaged loss across GPUs\n",
    "                    loss = outputs.loss.mean() / self.grad_accum_steps\n",
    "                \n",
    "                self.scaler.scale(loss).backward()\n",
    "                \n",
    "                if (step + 1) % self.grad_accum_steps == 0:\n",
    "                    self.scaler.unscale_(self.optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(\n",
    "                        self._get_trainable_params(),\n",
    "                        self.config.max_grad_norm\n",
    "                    )\n",
    "                    self.scaler.step(self.optimizer)\n",
    "                    self.scaler.update()\n",
    "                    self.scheduler.step()\n",
    "                    self.optimizer.zero_grad()\n",
    "            else:\n",
    "                outputs = self.model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=labels\n",
    "                )\n",
    "                loss = outputs.loss.mean() / self.grad_accum_steps\n",
    "                \n",
    "                loss.backward()\n",
    "                \n",
    "                if (step + 1) % self.grad_accum_steps == 0:\n",
    "                    torch.nn.utils.clip_grad_norm_(\n",
    "                        self._get_trainable_params(),\n",
    "                        self.config.max_grad_norm\n",
    "                    )\n",
    "                    self.optimizer.step()\n",
    "                    self.scheduler.step()\n",
    "                    self.optimizer.zero_grad()\n",
    "            \n",
    "            total_loss += loss.item() * self.grad_accum_steps\n",
    "            num_batches += 1\n",
    "            \n",
    "            progress_bar.set_postfix({\n",
    "                'loss': f'{loss.item() * self.grad_accum_steps:.4f}',\n",
    "                'lr': f'{self.scheduler.get_last_lr()[0]:.2e}'\n",
    "            })\n",
    "        \n",
    "        # Handle remaining gradients\n",
    "        remaining = len(self.train_loader) % self.grad_accum_steps\n",
    "        if remaining != 0:\n",
    "            if self.use_fp16:\n",
    "                self.scaler.unscale_(self.optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(\n",
    "                    self._get_trainable_params(),\n",
    "                    self.config.max_grad_norm\n",
    "                )\n",
    "                self.scaler.step(self.optimizer)\n",
    "                self.scaler.update()\n",
    "            else:\n",
    "                torch.nn.utils.clip_grad_norm_(\n",
    "                    self._get_trainable_params(),\n",
    "                    self.config.max_grad_norm\n",
    "                )\n",
    "                self.optimizer.step()\n",
    "            self.scheduler.step()\n",
    "            self.optimizer.zero_grad()\n",
    "        \n",
    "        return total_loss / num_batches\n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"Full training loop.\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Starting Training\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for epoch in range(self.config.num_epochs):\n",
    "            epoch_start = time.time()\n",
    "            \n",
    "            train_loss = self.train_epoch(epoch)\n",
    "            self.history['train_loss'].append(train_loss)\n",
    "            \n",
    "            current_lr = self.scheduler.get_last_lr()[0]\n",
    "            self.history['learning_rate'].append(current_lr)\n",
    "            \n",
    "            epoch_time = time.time() - epoch_start\n",
    "            \n",
    "            print(f\"\\nEpoch {epoch+1}/{self.config.num_epochs} - \"\n",
    "                  f\"Train Loss: {train_loss:.4f} - \"\n",
    "                  f\"LR: {current_lr:.2e} - \"\n",
    "                  f\"Time: {epoch_time:.1f}s\")\n",
    "            \n",
    "            # Memory report\n",
    "            if torch.cuda.is_available():\n",
    "                for i in range(config.num_gpus):\n",
    "                    allocated = torch.cuda.memory_allocated(i) / 1024**3\n",
    "                    reserved = torch.cuda.memory_reserved(i) / 1024**3\n",
    "                    print(f\"  GPU {i} memory: {allocated:.1f} GB allocated, {reserved:.1f} GB reserved\")\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"\\nTraining Complete! Total time: {total_time/60:.1f} minutes\")\n",
    "        \n",
    "        return self.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(config.seed)\n",
    "\n",
    "# Initialize trainer and train\n",
    "trainer = Trainer(model, config, train_loader)\n",
    "history = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "Evaluation Module\n",
    "\n",
    "Metrics: Accuracy, Macro/Weighted F1, Per-class report, Confusion matrix\n",
    "\"\"\"\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, test_loader, config):\n",
    "    \"\"\"Comprehensive evaluation on test set.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Evaluating on Test Set\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "        input_ids = batch['input_ids'].to(config.device)\n",
    "        attention_mask = batch['attention_mask'].to(config.device)\n",
    "        labels = batch['label'].to(config.device)\n",
    "        \n",
    "        if config.use_fp16:\n",
    "            with autocast(\"cuda\"):\n",
    "                outputs = model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=labels\n",
    "                )\n",
    "        else:\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "        \n",
    "        # Handle DataParallel loss\n",
    "        loss = outputs.loss.mean() if outputs.loss.dim() > 0 else outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "        \n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_predictions, average='macro'\n",
    "    )\n",
    "    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_predictions, average='weighted'\n",
    "    )\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    \n",
    "    label_names = get_label_names()\n",
    "    report = classification_report(all_labels, all_predictions, target_names=label_names, digits=4)\n",
    "    conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EVALUATION RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\n[Overall Metrics]\")\n",
    "    print(f\"  Test Loss: {avg_loss:.4f}\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"\\n[Macro Averages]\")\n",
    "    print(f\"  Precision: {precision_macro:.4f}\")\n",
    "    print(f\"  Recall: {recall_macro:.4f}\")\n",
    "    print(f\"  F1 Score: {f1_macro:.4f}\")\n",
    "    print(f\"\\n[Weighted Averages]\")\n",
    "    print(f\"  Precision: {precision_weighted:.4f}\")\n",
    "    print(f\"  Recall: {recall_weighted:.4f}\")\n",
    "    print(f\"  F1 Score: {f1_weighted:.4f}\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CLASSIFICATION REPORT (Per-Class)\")\n",
    "    print(\"=\"*60)\n",
    "    print(report)\n",
    "    \n",
    "    return {\n",
    "        'test_loss': avg_loss,\n",
    "        'accuracy': accuracy,\n",
    "        'precision_macro': precision_macro,\n",
    "        'recall_macro': recall_macro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'precision_weighted': precision_weighted,\n",
    "        'recall_weighted': recall_weighted,\n",
    "        'f1_weighted': f1_weighted,\n",
    "        'classification_report': report,\n",
    "        'confusion_matrix': conf_matrix,\n",
    "        'predictions': all_predictions,\n",
    "        'labels': all_labels,\n",
    "        'label_names': label_names\n",
    "    }\n",
    "\n",
    "\n",
    "# Evaluate\n",
    "results = evaluate(model, test_loader, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL RESULTS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"  Model: {config.model_name}\")\n",
    "print(f\"  GPUs: {config.num_gpus} \u00d7 T4\")\n",
    "print(f\"  Test Accuracy: {results['accuracy']:.4f} ({results['accuracy']*100:.2f}%)\")\n",
    "print(f\"  Macro F1 Score: {results['f1_macro']:.4f}\")\n",
    "print(f\"  Weighted F1 Score: {results['f1_weighted']:.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if config.save_model:\n",
    "    os.makedirs(config.output_dir, exist_ok=True)\n",
    "    \n",
    "    # Unwrap DataParallel if needed\n",
    "    save_model = model.module if hasattr(model, 'module') else model\n",
    "    \n",
    "    # Save model\n",
    "    model_path = os.path.join(config.output_dir, \"model\")\n",
    "    save_model.save_pretrained(model_path)\n",
    "    print(f\"Model saved to: {model_path}\")\n",
    "    \n",
    "    # Save tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "    tokenizer.save_pretrained(model_path)\n",
    "    print(f\"Tokenizer saved to: {model_path}\")\n",
    "    \n",
    "    # Save training history\n",
    "    history_path = os.path.join(config.output_dir, \"training_history.json\")\n",
    "    with open(history_path, 'w') as f:\n",
    "        json.dump(history, f, indent=2)\n",
    "    print(f\"Training history saved to: {history_path}\")\n",
    "    \n",
    "    # Save evaluation metrics\n",
    "    metrics = {\n",
    "        'model': config.model_name,\n",
    "        'num_gpus': config.num_gpus,\n",
    "        'test_loss': results['test_loss'],\n",
    "        'accuracy': results['accuracy'],\n",
    "        'precision_macro': results['precision_macro'],\n",
    "        'recall_macro': results['recall_macro'],\n",
    "        'f1_macro': results['f1_macro'],\n",
    "        'precision_weighted': results['precision_weighted'],\n",
    "        'recall_weighted': results['recall_weighted'],\n",
    "        'f1_weighted': results['f1_weighted'],\n",
    "    }\n",
    "    metrics_path = os.path.join(config.output_dir, \"evaluation_metrics.json\")\n",
    "    with open(metrics_path, 'w') as f:\n",
    "        json.dump(metrics, f, indent=2)\n",
    "    print(f\"Evaluation metrics saved to: {metrics_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}